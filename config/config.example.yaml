# the teams or use cases accessing Azure OpenAI (aka. "clients") and their keys
# notes: - each client must have a unique key. PowerProxy identifies clients by the given key.
#        - leave empty if Azure AD auth against Azure OpenAI is used.
clients:
  - name: Team 1
    description: An example team named 'Team 1'.
    key: 28ef59ae30342978f81c4ad96ce47ab
    max_tokens_per_minute_in_k: 10
  - name: Team 2
    description: An example team named 'Team 2'.
    key: 1113456789abcdef0123456789abcde
    max_tokens_per_minute_in_k: 10
  - name: Test Script Client 1
    description: Used by the included test scripts. Remove this client in production scenarios.
    key: 04ae14bc78184621d37f1ce57a52eb7
    max_tokens_per_minute_in_k: 10
  - name: Test Script Client 2
    description: Used by the included test scripts. Remove this client in production scenarios.
    key: 72bd81ef32763530b29e3da63d46ad6
    max_tokens_per_minute_in_k: 10

# if set, the proxy will always use the specified client for all requests
# notes: - this is required when Azure AD auth against Azure OpenAI is used because there is no
#          other way to identify the client then.
#        - leave empty ("") when API key authentication is used.
# example: Some Team
#fixed_client:

# defines the plugins enabled for the proxy
plugins:
  - name: LimitUsage
    # remove the redis field if no redis synchronization is desired
    # note: do that only in case of a single PowerProxy worker where no synchronization is needed
    redis:
      redis_host: <will be set by deployment script>
      redis_password: <will be set by deployment script>
  - name: LogUsageToConsole
  - name: LogUsageToCsvFile
  - name: LogUsageToLogAnalytics
    log_ingestion_endpoint: <will be set by deployment script>
    data_collection_rule_id: <will be set by deployment script>
    # by default, we use the managed identity in the resource group to auth against Log Analytics.
    # if the managed identity cannot be used, as an alternative, credentials of a service principal
    # can be specified here. make sure that the managed identity/service principle have the
    # "Monitoring Metrics Publisher" role assigned to the Data Collection Rule (it might take up
    # to 30 minutes to become effective after configuration).
    #credential_tenant_id: ___
    #credential_client_id: ___
    #credential_client_secret: ___

# Azure OpenAI
aoai:
  endpoints:
    - name: Some Endpoint
      url: https://___.openai.azure.com/
      # not required when Azure OpenAI's Azure AD/Entra ID authentication is used
      key: ___
      # fraction of non-streaming requests handled
      # 0   = endpoint will handle no non-streaming request
      # 0.7 = endpoint will handle 70% of the non-streaming requests it gets
      # 1   = endpoint will handle all non-streaming request it gets
      non_streaming_fraction: 1
      # optional: specify a list of deployments availabe on this endpoint
      #deployments:
      #- name: gpt-35-turbo
      #- name: gpt-4-vision-preview

    - name: Another Endpoint
      url: https://___.openai.azure.com/
      # not required when Azure OpenAI's Azure AD/Entra ID authentication is used
      key: ___
      # fraction of non-streaming requests handled
      # 0   = endpoint will handle no non-streaming request
      # 0.7 = endpoint will handle 70% of the non-streaming requests it gets
      # 1   = endpoint will handle all non-streaming request it gets
      non_streaming_fraction: 1
      # optional: specify a list of deployments availabe on this endpoint
      #deployments:
      #- name: gpt-35-turbo

  # # alternatively, specify a mock response to be used instead of the real response from
  # # Azure OpenAI
  # # note: use this for testing PowerProxy's scalability
  # mock_response:
  #   ms_to_wait_before_return: 1000
  #   json: {
  #     "id": "chatcmpl-87lITNUXLFIBHyDu3jFTtgOibcAxz",
  #     "object": "chat.completion",
  #     "created": 1696860797,
  #     "model": "gpt-35-turbo",
  #     "choices": [
  #       {
  #         "index": 0,
  #         "finish_reason": "stop",
  #         "message": {
  #           "role": "assistant",
  #           "content": "I'm a mock response and not a real answer from Azure OpenAI."
  #         }
  #       }
  #     ],
  #     "usage": {
  #       "completion_tokens": 16,
  #       "prompt_tokens": 61,
  #       "total_tokens": 77
  #     }
  #   }

# id of the Azure subscription where the proxy shall be deployed to
azure_subscription_id: ___

# region to which the proxy shall be deployed to Azure
# example: westeurope
region: ___

# resource group to which the proxy shall be deployed to Azure
# example: PowerProxy-AOAI
resource_group: ___

# unique prefix to prepend to certain resource names to avoid naming conflicts.
# example: abcde
unique_prefix: ___

# id of the user-assigned managed identity
# note: PowerProxy will assume a system-assigned managed identity if not specified
user_assigned_managed_identity_client_id: <will be set by deployment script>
